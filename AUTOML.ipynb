{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da7e8cef",
   "metadata": {
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1732072240974,
     "user": {
      "displayName": "Grayson K Merritt",
      "userId": "01135952421235413590"
     },
     "user_tz": 360
    },
    "id": "da7e8cef"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b498206",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1122,
     "status": "ok",
     "timestamp": 1732072242534,
     "user": {
      "displayName": "Grayson K Merritt",
      "userId": "01135952421235413590"
     },
     "user_tz": 360
    },
    "id": "4b498206",
    "outputId": "a0db9fe8-f68c-40fb-8284-e9e5a7d74482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after dropping unnecessary columns, replacing category names, and saving Apache probabilities:\n",
      "    age    bmi  elective_surgery  ethnicity gender  height  \\\n",
      "0  68.0  22.73                 0  Caucasian      M   180.3   \n",
      "1  77.0  27.42                 0  Caucasian      F   160.0   \n",
      "2  25.0  31.95                 0  Caucasian      F   172.7   \n",
      "3  81.0  22.64                 1  Caucasian      F   165.1   \n",
      "4  19.0    NaN                 0  Caucasian      M   188.0   \n",
      "\n",
      "            icu_admit_source icu_stay_type      icu_type  pre_icu_los_days  \\\n",
      "0                      Floor         admit         CTICU          0.541667   \n",
      "1                      Floor         admit  Med-Surg ICU          0.927778   \n",
      "2       Accident & Emergency         admit  Med-Surg ICU          0.000694   \n",
      "3  Operating Room / Recovery         admit         CTICU          0.000694   \n",
      "4       Accident & Emergency         admit  Med-Surg ICU          0.073611   \n",
      "\n",
      "   ...  cirrhosis  diabetes_mellitus  hepatic_failure  immunosuppression  \\\n",
      "0  ...        0.0                1.0              0.0                0.0   \n",
      "1  ...        0.0                1.0              0.0                0.0   \n",
      "2  ...        0.0                0.0              0.0                0.0   \n",
      "3  ...        0.0                0.0              0.0                0.0   \n",
      "4  ...        0.0                0.0              0.0                0.0   \n",
      "\n",
      "   leukemia  lymphoma  solid_tumor_with_metastasis  apache_3j_bodysystem  \\\n",
      "0       0.0       0.0                          0.0                Sepsis   \n",
      "1       0.0       0.0                          0.0           Respiratory   \n",
      "2       0.0       0.0                          0.0             Metabolic   \n",
      "3       0.0       0.0                          0.0        Cardiovascular   \n",
      "4       0.0       0.0                          0.0                Trauma   \n",
      "\n",
      "   apache_2_bodysystem  hospital_death  \n",
      "0       Cardiovascular               0  \n",
      "1          Respiratory               0  \n",
      "2            Metabolic               0  \n",
      "3       Cardiovascular               0  \n",
      "4               Trauma               0  \n",
      "\n",
      "[5 rows x 77 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: Load Dataset and Initial Cleaning ---\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "cols_to_drop = ['encounter_id', 'patient_id', 'hospital_id', 'icu_id', 'Unnamed: 83', 'gcs_unable_apache']\n",
    "data.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# **Step 1: Replace \"Undefined diagnoses\" with \"Undefined Diagnoses\" in 'apache_2_bodysystem'**\n",
    "# This ensures consistency in category naming\n",
    "data['apache_2_bodysystem'] = data['apache_2_bodysystem'].replace('Undefined diagnoses', 'Undefined Diagnoses')\n",
    "\n",
    "# Save 'apache_4a_hospital_death_prob' and 'apache_4a_icu_death_prob' in a separate DataFrame\n",
    "apache_probs = data[['apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob']].copy()\n",
    "\n",
    "# Drop these columns from the main dataset\n",
    "data.drop(columns=['apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob'], inplace=True)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(\"Data after dropping unnecessary columns, replacing category names, and saving Apache probabilities:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d021ca1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1732072242534,
     "user": {
      "displayName": "Grayson K Merritt",
      "userId": "01135952421235413590"
     },
     "user_tz": 360
    },
    "id": "8d021ca1",
    "outputId": "55deaf8a-4b87-4ce8-c2fb-5dd7c29e6353"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data shape before dropping missing values: (61955, 77)\n",
      "Data shape after dropping missing values: (61955, 77)\n"
     ]
    }
   ],
   "source": [
    "# Drop any rows that have missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "\n",
    "print(f\"\\nData shape before dropping missing values: {data.shape}\")\n",
    "print(f\"Data shape after dropping missing values: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1346dc5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1732072242534,
     "user": {
      "displayName": "Grayson K Merritt",
      "userId": "01135952421235413590"
     },
     "user_tz": 360
    },
    "id": "f1346dc5",
    "outputId": "174bc520-5e10-4296-925f-2c3a8f3b66af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Feature Engineering:\n",
      "     age        bmi  elective_surgery  ethnicity gender  height  \\\n",
      "0   68.0  22.730000                 0  Caucasian      M   180.3   \n",
      "1   77.0  27.420000                 0  Caucasian      F   160.0   \n",
      "5   67.0  27.560000                 0  Caucasian      M   190.5   \n",
      "10  72.0  28.257052                 1   Hispanic      F   154.9   \n",
      "17  46.0  25.845717                 0   Hispanic      M   167.6   \n",
      "\n",
      "             icu_admit_source icu_stay_type      icu_type  pre_icu_los_days  \\\n",
      "0                       Floor         admit         Other          0.541667   \n",
      "1                       Floor         admit  Med-Surg ICU          0.927778   \n",
      "5        Accident & Emergency         admit  Med-Surg ICU          0.000694   \n",
      "10  Operating Room / Recovery         admit  Med-Surg ICU          0.004861   \n",
      "17       Accident & Emergency         admit         Other          0.000000   \n",
      "\n",
      "    ...  h1_sysbp_noninvasive_min  d1_glucose_max  d1_glucose_min  \\\n",
      "0   ...                     115.0           168.0           109.0   \n",
      "1   ...                      71.0           145.0           128.0   \n",
      "5   ...                     143.0           156.0           125.0   \n",
      "10  ...                     114.0           158.0           133.0   \n",
      "17  ...                     115.0           143.0           143.0   \n",
      "\n",
      "    d1_potassium_max  d1_potassium_min  apache_3j_bodysystem  \\\n",
      "0                4.0               3.4                Sepsis   \n",
      "1                4.2               3.8           Respiratory   \n",
      "5                3.9               3.7          Neurological   \n",
      "10               4.2               4.2           Respiratory   \n",
      "17               4.9               4.9           Respiratory   \n",
      "\n",
      "    apache_2_bodysystem  hospital_death  comorbidity_count  gcs_total  \n",
      "0        Cardiovascular               0                  1       13.0  \n",
      "1           Respiratory               0                  1        5.0  \n",
      "5            Neurologic               0                  1       15.0  \n",
      "10          Respiratory               0                  1       15.0  \n",
      "17          Respiratory               0                  0        6.0  \n",
      "\n",
      "[5 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "# Handle comorbidity variables\n",
    "comorbidity_vars = [\n",
    "    'aids', 'cirrhosis', 'diabetes_mellitus', 'hepatic_failure',\n",
    "    'immunosuppression', 'leukemia', 'lymphoma', 'solid_tumor_with_metastasis'\n",
    "]\n",
    "\n",
    "# Ensure comorbidity variables are integers\n",
    "data[comorbidity_vars] = data[comorbidity_vars].astype(int)\n",
    "\n",
    "# Compute comorbidity count\n",
    "data['comorbidity_count'] = data[comorbidity_vars].sum(axis=1)\n",
    "\n",
    "# Handle GCS (Glasgow Coma Scale) variables\n",
    "gcs_vars = ['gcs_eyes_apache', 'gcs_motor_apache', 'gcs_verbal_apache']\n",
    "\n",
    "# Convert GCS variables to numeric if not already\n",
    "data[gcs_vars] = data[gcs_vars].apply(pd.to_numeric)\n",
    "\n",
    "# Compute GCS total\n",
    "data['gcs_total'] = data[gcs_vars].sum(axis=1)\n",
    "\n",
    "# Re-express categorical variables by combining certain categories\n",
    "\n",
    "# Ethnicity: Combine 'Asian', 'Native American', 'Other/Unknown' into 'Other'\n",
    "ethnicities_to_combine = ['Asian', 'Native American', 'Other/Unknown']\n",
    "data['ethnicity'] = data['ethnicity'].apply(\n",
    "    lambda x: x if x not in ethnicities_to_combine else 'Other'\n",
    ")\n",
    "\n",
    "# ICU Admit Source: Combine 'Other ICU' into 'Other'\n",
    "icu_admit_sources_to_combine = ['Other ICU']\n",
    "data['icu_admit_source'] = data['icu_admit_source'].apply(\n",
    "    lambda x: x if x not in icu_admit_sources_to_combine else 'Other'\n",
    ")\n",
    "\n",
    "# ICU Type: Combine 'SICU', 'CTICU', 'CSICU' into 'Other'\n",
    "icu_types_to_combine = ['SICU', 'CTICU', 'CSICU']\n",
    "data['icu_type'] = data['icu_type'].apply(\n",
    "    lambda x: x if x not in icu_types_to_combine else 'Other'\n",
    ")\n",
    "\n",
    "# APACHE 3J Bodysystem: Combine specific categories into 'Other'\n",
    "apache_3j_bodysystem_to_combine = [\n",
    "    'Gynecological',\n",
    "    'Musculoskeletal/Skin',\n",
    "    'Hematological',\n",
    "    'Genitourinary',\n",
    "    'Trauma',\n",
    "    'Metabolic'\n",
    "]\n",
    "data['apache_3j_bodysystem'] = data['apache_3j_bodysystem'].apply(\n",
    "    lambda x: x if x not in apache_3j_bodysystem_to_combine else 'Other'\n",
    ")\n",
    "\n",
    "# Drop individual comorbidity and GCS columns since we have the totals\n",
    "data.drop(columns=comorbidity_vars + gcs_vars, inplace=True)\n",
    "\n",
    "# Display the first few rows to verify feature engineering\n",
    "print(\"Data after Feature Engineering:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfb8499b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1732072243054,
     "user": {
      "displayName": "Grayson K Merritt",
      "userId": "01135952421235413590"
     },
     "user_tz": 360
    },
    "id": "dfb8499b",
    "outputId": "76aaf7d4-6c57-49fa-de57-f2646f16a42b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Numerical Features:\n",
      "['age', 'bmi', 'elective_surgery', 'height', 'pre_icu_los_days', 'weight', 'apache_2_diagnosis', 'apache_3j_diagnosis', 'apache_post_operative', 'arf_apache', 'heart_rate_apache', 'intubated_apache', 'map_apache', 'resprate_apache', 'temp_apache', 'ventilated_apache', 'd1_diasbp_max', 'd1_diasbp_min', 'd1_diasbp_noninvasive_max', 'd1_diasbp_noninvasive_min', 'd1_heartrate_max', 'd1_heartrate_min', 'd1_mbp_max', 'd1_mbp_min', 'd1_mbp_noninvasive_max', 'd1_mbp_noninvasive_min', 'd1_resprate_max', 'd1_resprate_min', 'd1_spo2_max', 'd1_spo2_min', 'd1_sysbp_max', 'd1_sysbp_min', 'd1_sysbp_noninvasive_max', 'd1_sysbp_noninvasive_min', 'd1_temp_max', 'd1_temp_min', 'h1_diasbp_max', 'h1_diasbp_min', 'h1_diasbp_noninvasive_max', 'h1_diasbp_noninvasive_min', 'h1_heartrate_max', 'h1_heartrate_min', 'h1_mbp_max', 'h1_mbp_min', 'h1_mbp_noninvasive_max', 'h1_mbp_noninvasive_min', 'h1_resprate_max', 'h1_resprate_min', 'h1_spo2_max', 'h1_spo2_min', 'h1_sysbp_max', 'h1_sysbp_min', 'h1_sysbp_noninvasive_max', 'h1_sysbp_noninvasive_min', 'd1_glucose_max', 'd1_glucose_min', 'd1_potassium_max', 'd1_potassium_min', 'comorbidity_count', 'gcs_total']\n",
      "\n",
      "Categorical Features:\n",
      "['ethnicity', 'gender', 'icu_admit_source', 'icu_stay_type', 'icu_type', 'apache_2_bodysystem', 'apache_3j_bodysystem']\n",
      "\n",
      "Binary Categorical Features:\n",
      "['gender']\n",
      "\n",
      "Summary Statistics of Continuous Numerical Features:\n",
      "                age           bmi  elective_surgery        height  \\\n",
      "count  61955.000000  61955.000000      61955.000000  61955.000000   \n",
      "mean      62.479655     29.302444          0.159325    169.763384   \n",
      "std       16.727255      8.343413          0.365982     10.753394   \n",
      "min       16.000000     14.844926          0.000000    137.200000   \n",
      "25%       53.000000     23.706122          0.000000    162.560000   \n",
      "50%       65.000000     27.771653          0.000000    170.100000   \n",
      "75%       75.000000     33.086879          0.000000    177.800000   \n",
      "max       89.000000     67.814990          1.000000    195.590000   \n",
      "\n",
      "       pre_icu_los_days        weight  apache_2_diagnosis  \\\n",
      "count      61955.000000  61955.000000        61955.000000   \n",
      "mean           0.822111     84.448021          181.938278   \n",
      "std            2.396905     25.146599           85.701631   \n",
      "min           -0.244444     38.600000          101.000000   \n",
      "25%            0.036806     67.100000          113.000000   \n",
      "50%            0.136806     80.740000          122.000000   \n",
      "75%            0.389583     97.500000          301.000000   \n",
      "max           73.022917    186.000000          308.000000   \n",
      "\n",
      "       apache_3j_diagnosis  apache_post_operative    arf_apache  ...  \\\n",
      "count         61955.000000           61955.000000  61955.000000  ...   \n",
      "mean            547.861361               0.181519      0.030264  ...   \n",
      "std             450.768800               0.385451      0.171314  ...   \n",
      "min             101.010000               0.000000      0.000000  ...   \n",
      "25%             206.010000               0.000000      0.000000  ...   \n",
      "50%             409.020000               0.000000      0.000000  ...   \n",
      "75%             703.030000               0.000000      0.000000  ...   \n",
      "max            2201.050000               1.000000      1.000000  ...   \n",
      "\n",
      "       h1_sysbp_max  h1_sysbp_min  h1_sysbp_noninvasive_max  \\\n",
      "count  61955.000000  61955.000000              61955.000000   \n",
      "mean     132.821144    115.903688                132.713034   \n",
      "std       27.585256     26.519679                 27.573993   \n",
      "min       75.000000     53.000000                 75.000000   \n",
      "25%      113.000000     97.000000                113.000000   \n",
      "50%      130.000000    114.000000                130.000000   \n",
      "75%      150.000000    133.000000                150.000000   \n",
      "max      223.000000    194.000000                223.000000   \n",
      "\n",
      "       h1_sysbp_noninvasive_min  d1_glucose_max  d1_glucose_min  \\\n",
      "count              61955.000000    61955.000000    61955.000000   \n",
      "mean                 115.849778      175.979195      113.882479   \n",
      "std                   26.510664       88.855958       37.681962   \n",
      "min                   53.000000       73.000000       33.000000   \n",
      "25%                   97.000000      117.000000       90.000000   \n",
      "50%                  114.000000      150.000000      107.000000   \n",
      "75%                  133.000000      203.000000      130.000000   \n",
      "max                  195.000000      611.000000      288.000000   \n",
      "\n",
      "       d1_potassium_max  d1_potassium_min  comorbidity_count     gcs_total  \n",
      "count      61955.000000      61955.000000       61955.000000  61955.000000  \n",
      "mean           4.238361          3.932157           0.334049     12.808942  \n",
      "std            0.669631          0.582967           0.560285      3.532196  \n",
      "min            2.800000          2.400000           0.000000      3.000000  \n",
      "25%            3.800000          3.600000           0.000000     12.000000  \n",
      "50%            4.100000          3.900000           0.000000     15.000000  \n",
      "75%            4.600000          4.300000           1.000000     15.000000  \n",
      "max            7.000000          5.800000           4.000000     15.000000  \n",
      "\n",
      "[8 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 6: Display Numerical and Categorical Features Separately ---\n",
    "\n",
    "# **Step 1: Define Categorical Features Before Encoding**\n",
    "# It's crucial to define which features are categorical based on your understanding of the data.\n",
    "# Adjust this list based on your dataset's actual categorical features.\n",
    "\n",
    "categorical_features = [\n",
    "    'ethnicity', 'gender', 'icu_admit_source', 'icu_stay_type',\n",
    "    'icu_type', 'apache_2_bodysystem', 'apache_3j_bodysystem'\n",
    "]\n",
    "\n",
    "# **Step 2: Identify Numerical Features (Excluding the Target Variable)**\n",
    "numerical_features = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'hospital_death' in numerical_features:\n",
    "    numerical_features.remove('hospital_death')\n",
    "\n",
    "# **Step 3: Differentiate Between Binary and Continuous Numerical Features**\n",
    "# Binary categorical features are those categorical features with exactly two unique values\n",
    "binary_columns = [col for col in categorical_features if data[col].nunique() == 2]\n",
    "# Continuous numerical features are the remaining numerical features not in binary_columns\n",
    "continuous_numerical_features = [col for col in numerical_features if col not in binary_columns]\n",
    "\n",
    "# **Step 4: Print Feature Lists**\n",
    "print(\"Continuous Numerical Features:\")\n",
    "print(continuous_numerical_features)\n",
    "\n",
    "print(\"\\nCategorical Features:\")\n",
    "print(categorical_features)\n",
    "\n",
    "print(\"\\nBinary Categorical Features:\")\n",
    "print(binary_columns)\n",
    "\n",
    "# **Step 5: Summary Statistics for Continuous Numerical Features**\n",
    "if continuous_numerical_features:\n",
    "    print(\"\\nSummary Statistics of Continuous Numerical Features:\")\n",
    "    print(data[continuous_numerical_features].describe())\n",
    "else:\n",
    "    print(\"\\nNo Continuous Numerical Features to display.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1846d6ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2455,
     "status": "ok",
     "timestamp": 1732072245507,
     "user": {
      "displayName": "Grayson K Merritt",
      "userId": "01135952421235413590"
     },
     "user_tz": 360
    },
    "id": "1846d6ca",
    "outputId": "ed631609-2bdf-4595-d420-8d874c629b6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features to Encode:\n",
      "['ethnicity', 'gender', 'icu_admit_source', 'icu_stay_type', 'icu_type', 'apache_2_bodysystem', 'apache_3j_bodysystem']\n",
      "\n",
      "Data Types After Label Encoding:\n",
      "age                     float64\n",
      "bmi                     float64\n",
      "elective_surgery          int64\n",
      "ethnicity                 int32\n",
      "gender                    int32\n",
      "                         ...   \n",
      "apache_3j_bodysystem      int32\n",
      "apache_2_bodysystem       int32\n",
      "hospital_death            int64\n",
      "comorbidity_count         int64\n",
      "gcs_total               float64\n",
      "Length: 68, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 10: Encode Categorical Variables Appropriately ---\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identify categorical features (predefined)\n",
    "print(\"Categorical Features to Encode:\")\n",
    "print(categorical_features)\n",
    "\n",
    "# Initialize LabelEncoders for each categorical column\n",
    "label_encoders = {}\n",
    "\n",
    "# Apply Label Encoding to all categorical features\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le  # Save the encoder for future use (e.g., during inference)\n",
    "\n",
    "# Verify that all categorical features have been encoded\n",
    "print(\"\\nData Types After Label Encoding:\")\n",
    "print(data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3075dcd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1732072245507,
     "user": {
      "displayName": "Grayson K Merritt",
      "userId": "01135952421235413590"
     },
     "user_tz": 360
    },
    "id": "c3075dcd",
    "outputId": "d222ba8f-a344-4290-cc59-6b1e214970f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Label Encoding Explained:**\n",
      "\n",
      "Label Encoding is a technique used to convert categorical variables into numerical form so that machine learning algorithms can process them.\n",
      "Each unique category in a feature is assigned an integer value.\n",
      "\n",
      "**Example:**\n",
      "For a feature 'gender' with categories ['Male', 'Female'], Label Encoding might assign:\n",
      "- 'Male' -> 0\n",
      "- 'Female' -> 1\n",
      "\n",
      "**Important Note:**\n",
      "Label Encoding does not preserve any ordinal relationship unless the categories inherently have one.\n",
      "For purely nominal categorical variables, One-Hot Encoding is often preferred to avoid introducing unintended ordinal relationships.\n",
      "\n",
      "Below, we'll display the mapping of each categorical feature from its original categories to the encoded numerical values.\n",
      "\n",
      "\n",
      "**Feature: ethnicity**\n",
      "  0: African American\n",
      "  1: Caucasian\n",
      "  2: Hispanic\n",
      "  3: Other\n",
      "\n",
      "**Feature: gender**\n",
      "  0: F\n",
      "  1: M\n",
      "\n",
      "**Feature: icu_admit_source**\n",
      "  0: Accident & Emergency\n",
      "  1: Floor\n",
      "  2: Operating Room / Recovery\n",
      "  3: Other\n",
      "  4: Other Hospital\n",
      "\n",
      "**Feature: icu_stay_type**\n",
      "  0: admit\n",
      "  1: readmit\n",
      "  2: transfer\n",
      "\n",
      "**Feature: icu_type**\n",
      "  0: CCU-CTICU\n",
      "  1: Cardiac ICU\n",
      "  2: MICU\n",
      "  3: Med-Surg ICU\n",
      "  4: Neuro ICU\n",
      "  5: Other\n",
      "\n",
      "**Feature: apache_2_bodysystem**\n",
      "  0: Cardiovascular\n",
      "  1: Gastrointestinal\n",
      "  2: Haematologic\n",
      "  3: Metabolic\n",
      "  4: Neurologic\n",
      "  5: Renal/Genitourinary\n",
      "  6: Respiratory\n",
      "  7: Trauma\n",
      "  8: Undefined Diagnoses\n",
      "\n",
      "**Feature: apache_3j_bodysystem**\n",
      "  0: Cardiovascular\n",
      "  1: Gastrointestinal\n",
      "  2: Neurological\n",
      "  3: Other\n",
      "  4: Respiratory\n",
      "  5: Sepsis\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 11: Label Encoding Explanation and Mappings ---\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# **Step 1: Explanation of Label Encoding**\n",
    "print(\"\"\"\n",
    "**Label Encoding Explained:**\n",
    "\n",
    "Label Encoding is a technique used to convert categorical variables into numerical form so that machine learning algorithms can process them.\n",
    "Each unique category in a feature is assigned an integer value.\n",
    "\n",
    "**Example:**\n",
    "For a feature 'gender' with categories ['Male', 'Female'], Label Encoding might assign:\n",
    "- 'Male' -> 0\n",
    "- 'Female' -> 1\n",
    "\n",
    "**Important Note:**\n",
    "Label Encoding does not preserve any ordinal relationship unless the categories inherently have one.\n",
    "For purely nominal categorical variables, One-Hot Encoding is often preferred to avoid introducing unintended ordinal relationships.\n",
    "\n",
    "Below, we'll display the mapping of each categorical feature from its original categories to the encoded numerical values.\n",
    "\"\"\")\n",
    "\n",
    "# **Step 2: Display Label Encoding Mappings for Each Categorical Feature**\n",
    "for col, le in label_encoders.items():\n",
    "    print(f\"\\n**Feature: {col}**\")\n",
    "    mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    for category, code in mapping.items():\n",
    "        print(f\"  {code}: {category}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc4e6bc7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1732072245507,
     "user": {
      "displayName": "Grayson K Merritt",
      "userId": "01135952421235413590"
     },
     "user_tz": 360
    },
    "id": "dc4e6bc7",
    "outputId": "87698c40-c23e-4f5c-9d51-aa6e7b2b3586"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Processed Dataset Columns:\n",
      "['age', 'bmi', 'elective_surgery', 'ethnicity', 'gender', 'height', 'icu_admit_source', 'icu_stay_type', 'icu_type', 'pre_icu_los_days', 'weight', 'apache_2_diagnosis', 'apache_3j_diagnosis', 'apache_post_operative', 'arf_apache', 'heart_rate_apache', 'intubated_apache', 'map_apache', 'resprate_apache', 'temp_apache', 'ventilated_apache', 'd1_diasbp_max', 'd1_diasbp_min', 'd1_diasbp_noninvasive_max', 'd1_diasbp_noninvasive_min', 'd1_heartrate_max', 'd1_heartrate_min', 'd1_mbp_max', 'd1_mbp_min', 'd1_mbp_noninvasive_max', 'd1_mbp_noninvasive_min', 'd1_resprate_max', 'd1_resprate_min', 'd1_spo2_max', 'd1_spo2_min', 'd1_sysbp_max', 'd1_sysbp_min', 'd1_sysbp_noninvasive_max', 'd1_sysbp_noninvasive_min', 'd1_temp_max', 'd1_temp_min', 'h1_diasbp_max', 'h1_diasbp_min', 'h1_diasbp_noninvasive_max', 'h1_diasbp_noninvasive_min', 'h1_heartrate_max', 'h1_heartrate_min', 'h1_mbp_max', 'h1_mbp_min', 'h1_mbp_noninvasive_max', 'h1_mbp_noninvasive_min', 'h1_resprate_max', 'h1_resprate_min', 'h1_spo2_max', 'h1_spo2_min', 'h1_sysbp_max', 'h1_sysbp_min', 'h1_sysbp_noninvasive_max', 'h1_sysbp_noninvasive_min', 'd1_glucose_max', 'd1_glucose_min', 'd1_potassium_max', 'd1_potassium_min', 'apache_3j_bodysystem', 'apache_2_bodysystem', 'hospital_death', 'comorbidity_count', 'gcs_total']\n",
      "\n",
      "First 5 Rows of the Final Processed Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>icu_admit_source</th>\n",
       "      <th>icu_stay_type</th>\n",
       "      <th>icu_type</th>\n",
       "      <th>pre_icu_los_days</th>\n",
       "      <th>...</th>\n",
       "      <th>h1_sysbp_noninvasive_min</th>\n",
       "      <th>d1_glucose_max</th>\n",
       "      <th>d1_glucose_min</th>\n",
       "      <th>d1_potassium_max</th>\n",
       "      <th>d1_potassium_min</th>\n",
       "      <th>apache_3j_bodysystem</th>\n",
       "      <th>apache_2_bodysystem</th>\n",
       "      <th>hospital_death</th>\n",
       "      <th>comorbidity_count</th>\n",
       "      <th>gcs_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.0</td>\n",
       "      <td>22.730000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.0</td>\n",
       "      <td>27.420000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.927778</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67.0</td>\n",
       "      <td>27.560000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>190.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>...</td>\n",
       "      <td>143.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>72.0</td>\n",
       "      <td>28.257052</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>154.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>46.0</td>\n",
       "      <td>25.845717</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>167.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age        bmi  elective_surgery  ethnicity  gender  height  \\\n",
       "0   68.0  22.730000                 0          1       1   180.3   \n",
       "1   77.0  27.420000                 0          1       0   160.0   \n",
       "5   67.0  27.560000                 0          1       1   190.5   \n",
       "10  72.0  28.257052                 1          2       0   154.9   \n",
       "17  46.0  25.845717                 0          2       1   167.6   \n",
       "\n",
       "    icu_admit_source  icu_stay_type  icu_type  pre_icu_los_days  ...  \\\n",
       "0                  1              0         5          0.541667  ...   \n",
       "1                  1              0         3          0.927778  ...   \n",
       "5                  0              0         3          0.000694  ...   \n",
       "10                 2              0         3          0.004861  ...   \n",
       "17                 0              0         5          0.000000  ...   \n",
       "\n",
       "    h1_sysbp_noninvasive_min  d1_glucose_max  d1_glucose_min  \\\n",
       "0                      115.0           168.0           109.0   \n",
       "1                       71.0           145.0           128.0   \n",
       "5                      143.0           156.0           125.0   \n",
       "10                     114.0           158.0           133.0   \n",
       "17                     115.0           143.0           143.0   \n",
       "\n",
       "    d1_potassium_max  d1_potassium_min  apache_3j_bodysystem  \\\n",
       "0                4.0               3.4                     5   \n",
       "1                4.2               3.8                     4   \n",
       "5                3.9               3.7                     2   \n",
       "10               4.2               4.2                     4   \n",
       "17               4.9               4.9                     4   \n",
       "\n",
       "    apache_2_bodysystem  hospital_death  comorbidity_count  gcs_total  \n",
       "0                     0               0                  1       13.0  \n",
       "1                     6               0                  1        5.0  \n",
       "5                     4               0                  1       15.0  \n",
       "10                    6               0                  1       15.0  \n",
       "17                    6               0                  0        6.0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of the Final Processed Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 61955 entries, 0 to 91712\n",
      "Data columns (total 68 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   age                        61955 non-null  float64\n",
      " 1   bmi                        61955 non-null  float64\n",
      " 2   elective_surgery           61955 non-null  int64  \n",
      " 3   ethnicity                  61955 non-null  int32  \n",
      " 4   gender                     61955 non-null  int32  \n",
      " 5   height                     61955 non-null  float64\n",
      " 6   icu_admit_source           61955 non-null  int32  \n",
      " 7   icu_stay_type              61955 non-null  int32  \n",
      " 8   icu_type                   61955 non-null  int32  \n",
      " 9   pre_icu_los_days           61955 non-null  float64\n",
      " 10  weight                     61955 non-null  float64\n",
      " 11  apache_2_diagnosis         61955 non-null  float64\n",
      " 12  apache_3j_diagnosis        61955 non-null  float64\n",
      " 13  apache_post_operative      61955 non-null  int64  \n",
      " 14  arf_apache                 61955 non-null  float64\n",
      " 15  heart_rate_apache          61955 non-null  float64\n",
      " 16  intubated_apache           61955 non-null  float64\n",
      " 17  map_apache                 61955 non-null  float64\n",
      " 18  resprate_apache            61955 non-null  float64\n",
      " 19  temp_apache                61955 non-null  float64\n",
      " 20  ventilated_apache          61955 non-null  float64\n",
      " 21  d1_diasbp_max              61955 non-null  float64\n",
      " 22  d1_diasbp_min              61955 non-null  float64\n",
      " 23  d1_diasbp_noninvasive_max  61955 non-null  float64\n",
      " 24  d1_diasbp_noninvasive_min  61955 non-null  float64\n",
      " 25  d1_heartrate_max           61955 non-null  float64\n",
      " 26  d1_heartrate_min           61955 non-null  float64\n",
      " 27  d1_mbp_max                 61955 non-null  float64\n",
      " 28  d1_mbp_min                 61955 non-null  float64\n",
      " 29  d1_mbp_noninvasive_max     61955 non-null  float64\n",
      " 30  d1_mbp_noninvasive_min     61955 non-null  float64\n",
      " 31  d1_resprate_max            61955 non-null  float64\n",
      " 32  d1_resprate_min            61955 non-null  float64\n",
      " 33  d1_spo2_max                61955 non-null  float64\n",
      " 34  d1_spo2_min                61955 non-null  float64\n",
      " 35  d1_sysbp_max               61955 non-null  float64\n",
      " 36  d1_sysbp_min               61955 non-null  float64\n",
      " 37  d1_sysbp_noninvasive_max   61955 non-null  float64\n",
      " 38  d1_sysbp_noninvasive_min   61955 non-null  float64\n",
      " 39  d1_temp_max                61955 non-null  float64\n",
      " 40  d1_temp_min                61955 non-null  float64\n",
      " 41  h1_diasbp_max              61955 non-null  float64\n",
      " 42  h1_diasbp_min              61955 non-null  float64\n",
      " 43  h1_diasbp_noninvasive_max  61955 non-null  float64\n",
      " 44  h1_diasbp_noninvasive_min  61955 non-null  float64\n",
      " 45  h1_heartrate_max           61955 non-null  float64\n",
      " 46  h1_heartrate_min           61955 non-null  float64\n",
      " 47  h1_mbp_max                 61955 non-null  float64\n",
      " 48  h1_mbp_min                 61955 non-null  float64\n",
      " 49  h1_mbp_noninvasive_max     61955 non-null  float64\n",
      " 50  h1_mbp_noninvasive_min     61955 non-null  float64\n",
      " 51  h1_resprate_max            61955 non-null  float64\n",
      " 52  h1_resprate_min            61955 non-null  float64\n",
      " 53  h1_spo2_max                61955 non-null  float64\n",
      " 54  h1_spo2_min                61955 non-null  float64\n",
      " 55  h1_sysbp_max               61955 non-null  float64\n",
      " 56  h1_sysbp_min               61955 non-null  float64\n",
      " 57  h1_sysbp_noninvasive_max   61955 non-null  float64\n",
      " 58  h1_sysbp_noninvasive_min   61955 non-null  float64\n",
      " 59  d1_glucose_max             61955 non-null  float64\n",
      " 60  d1_glucose_min             61955 non-null  float64\n",
      " 61  d1_potassium_max           61955 non-null  float64\n",
      " 62  d1_potassium_min           61955 non-null  float64\n",
      " 63  apache_3j_bodysystem       61955 non-null  int32  \n",
      " 64  apache_2_bodysystem        61955 non-null  int32  \n",
      " 65  hospital_death             61955 non-null  int64  \n",
      " 66  comorbidity_count          61955 non-null  int64  \n",
      " 67  gcs_total                  61955 non-null  float64\n",
      "dtypes: float64(57), int32(7), int64(4)\n",
      "memory usage: 31.0 MB\n"
     ]
    }
   ],
   "source": [
    "# --- Final Cell: Inspect Final Processed Dataset Features ---\n",
    "\n",
    "# **Step 1: Display the List of Final Features**\n",
    "print(\"Final Processed Dataset Columns:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# **Step 2: Show the First Few Rows of the Processed Dataset**\n",
    "print(\"\\nFirst 5 Rows of the Final Processed Dataset:\")\n",
    "display(data.head())\n",
    "\n",
    "# **Step 3: Provide a Summary of the DataFrame**\n",
    "print(\"\\nSummary of the Final Processed Dataset:\")\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f503a603",
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1732072245507,
     "user": {
      "displayName": "Grayson K Merritt",
      "userId": "01135952421235413590"
     },
     "user_tz": 360
    },
    "id": "f503a603",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "120a3421",
   "metadata": {
    "id": "120a3421"
   },
   "source": [
    "## autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4763904",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3718,
     "status": "ok",
     "timestamp": 1732072249221,
     "user": {
      "displayName": "Grayson K Merritt",
      "userId": "01135952421235413590"
     },
     "user_tz": 360
    },
    "id": "d4763904",
    "outputId": "e60b67a9-c102-4f5d-9f74-8f7576bd2e64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flaml in c:\\users\\grays\\anaconda3\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: NumPy>=1.17 in c:\\users\\grays\\anaconda3\\lib\\site-packages (from flaml) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e294bce6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 353881,
     "status": "ok",
     "timestamp": 1732073330285,
     "user": {
      "displayName": "Grayson K Merritt",
      "userId": "01135952421235413590"
     },
     "user_tz": 360
    },
    "id": "e294bce6",
    "outputId": "e9f32055-4640-43ed-ac2b-64cb9da71bfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (61955, 67)\n",
      "Target shape: (61955,)\n",
      "Training features shape: (49564, 67)\n",
      "Testing features shape: (12391, 67)\n",
      "\n",
      "Applying SMOTE to handle class imbalance...\n",
      "After SMOTE, training features shape: (90786, 67)\n",
      "After SMOTE, training target distribution:\n",
      "hospital_death\n",
      "0    45393\n",
      "1    45393\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training FLAML AutoML model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Train FLAML AutoML model\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining FLAML AutoML model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m automl\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m=\u001b[39mX_train_smote, y_train\u001b[38;5;241m=\u001b[39my_train_smote, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mautoml_settings)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLAML AutoML training completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# View the best model\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flaml\\automl\\automl.py:1980\u001b[0m, in \u001b[0;36mAutoML.fit\u001b[1;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, preserve_checkpoint, early_stop, force_cancel, append_log, auto_augment, min_sample_size, use_ray, use_spark, free_mem_ratio, metric_constraints, custom_hp, time_col, cv_score_agg_func, skip_transform, mlflow_logging, fit_kwargs_by_estimator, mlflow_exp_name, **fit_kwargs)\u001b[0m\n\u001b[0;32m   1978\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m training_log_writer(log_file_name, append_log) \u001b[38;5;28;01mas\u001b[39;00m save_helper:\n\u001b[0;32m   1979\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_log \u001b[38;5;241m=\u001b[39m save_helper\n\u001b[1;32m-> 1980\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search()\n\u001b[0;32m   1981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1982\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flaml\\automl\\automl.py:2533\u001b[0m, in \u001b[0;36mAutoML._search\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2531\u001b[0m     state\u001b[38;5;241m.\u001b[39mbest_config \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39minit_config[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39minit_config \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m   2532\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_ray \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_spark \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m-> 2533\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_sequential()\n\u001b[0;32m   2534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_parallel()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flaml\\automl\\automl.py:2358\u001b[0m, in \u001b[0;36mAutoML._search_sequential\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2352\u001b[0m         search_state\u001b[38;5;241m.\u001b[39msearch_alg\u001b[38;5;241m.\u001b[39msearcher\u001b[38;5;241m.\u001b[39mset_search_properties(\n\u001b[0;32m   2353\u001b[0m             metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2354\u001b[0m             mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2355\u001b[0m             metric_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mbest_loss,\n\u001b[0;32m   2356\u001b[0m         )\n\u001b[0;32m   2357\u001b[0m start_run_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m-> 2358\u001b[0m analysis \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   2359\u001b[0m     search_state\u001b[38;5;241m.\u001b[39mtraining_function,\n\u001b[0;32m   2360\u001b[0m     search_alg\u001b[38;5;241m=\u001b[39msearch_state\u001b[38;5;241m.\u001b[39msearch_alg,\n\u001b[0;32m   2361\u001b[0m     time_budget_s\u001b[38;5;241m=\u001b[39mtime_budget_s,\n\u001b[0;32m   2362\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m   2363\u001b[0m     use_ray\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   2364\u001b[0m     use_spark\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   2365\u001b[0m     force_cancel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_force_cancel,\n\u001b[0;32m   2366\u001b[0m     mlflow_exp_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mlflow_exp_name,\n\u001b[0;32m   2367\u001b[0m     automl_info\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,),  \u001b[38;5;66;03m# pass automl info to tune.run\u001b[39;00m\n\u001b[0;32m   2368\u001b[0m     extra_tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautolog_extra_tag,\n\u001b[0;32m   2369\u001b[0m )\n\u001b[0;32m   2370\u001b[0m time_used \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_run_time\n\u001b[0;32m   2371\u001b[0m better \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flaml\\tune\\tune.py:877\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(evaluation_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, resource_attr, min_resource, max_resource, reduction_factor, scheduler, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray, use_spark, use_incumbent_result_in_evaluation, log_file_name, lexico_objectives, force_cancel, n_concurrent_trials, mlflow_exp_name, automl_info, extra_tag, **ray_args)\u001b[0m\n\u001b[0;32m    875\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m PySparkOvertimeMonitor(time_start, time_budget_s, force_cancel):\n\u001b[1;32m--> 877\u001b[0m     result \u001b[38;5;241m=\u001b[39m evaluation_function(trial_to_run\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m    878\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in tune: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_to_run\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flaml\\automl\\state.py:306\u001b[0m, in \u001b[0;36mAutoMLState._compute_with_config_base\u001b[1;34m(config_w_resource, state, estimator, is_report)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLAML_sample_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    290\u001b[0m budget \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mtime_budget \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m     )\n\u001b[0;32m    298\u001b[0m )\n\u001b[0;32m    300\u001b[0m (\n\u001b[0;32m    301\u001b[0m     trained_estimator,\n\u001b[0;32m    302\u001b[0m     val_loss,\n\u001b[0;32m    303\u001b[0m     metric_for_logging,\n\u001b[0;32m    304\u001b[0m     _,\n\u001b[0;32m    305\u001b[0m     pred_time,\n\u001b[1;32m--> 306\u001b[0m ) \u001b[38;5;241m=\u001b[39m compute_estimator(\n\u001b[0;32m    307\u001b[0m     sampled_X_train,\n\u001b[0;32m    308\u001b[0m     sampled_y_train,\n\u001b[0;32m    309\u001b[0m     state\u001b[38;5;241m.\u001b[39mX_val,\n\u001b[0;32m    310\u001b[0m     state\u001b[38;5;241m.\u001b[39my_val,\n\u001b[0;32m    311\u001b[0m     state\u001b[38;5;241m.\u001b[39mweight_val,\n\u001b[0;32m    312\u001b[0m     state\u001b[38;5;241m.\u001b[39mgroups_val,\n\u001b[0;32m    313\u001b[0m     state\u001b[38;5;241m.\u001b[39mtrain_time_limit \u001b[38;5;28;01mif\u001b[39;00m budget \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(budget, state\u001b[38;5;241m.\u001b[39mtrain_time_limit \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39minf),\n\u001b[0;32m    314\u001b[0m     state\u001b[38;5;241m.\u001b[39mkf,\n\u001b[0;32m    315\u001b[0m     config,\n\u001b[0;32m    316\u001b[0m     state\u001b[38;5;241m.\u001b[39mtask,\n\u001b[0;32m    317\u001b[0m     estimator,\n\u001b[0;32m    318\u001b[0m     state\u001b[38;5;241m.\u001b[39meval_method,\n\u001b[0;32m    319\u001b[0m     state\u001b[38;5;241m.\u001b[39mmetric,\n\u001b[0;32m    320\u001b[0m     state\u001b[38;5;241m.\u001b[39mbest_loss,\n\u001b[0;32m    321\u001b[0m     state\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    322\u001b[0m     state\u001b[38;5;241m.\u001b[39mlearner_classes\u001b[38;5;241m.\u001b[39mget(estimator),\n\u001b[0;32m    323\u001b[0m     state\u001b[38;5;241m.\u001b[39mcv_score_agg_func,\n\u001b[0;32m    324\u001b[0m     state\u001b[38;5;241m.\u001b[39mlog_training_metric,\n\u001b[0;32m    325\u001b[0m     this_estimator_kwargs,\n\u001b[0;32m    326\u001b[0m     state\u001b[38;5;241m.\u001b[39mfree_mem_ratio,\n\u001b[0;32m    327\u001b[0m )\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mretrain_final \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state\u001b[38;5;241m.\u001b[39mmodel_history:\n\u001b[0;32m    329\u001b[0m     trained_estimator\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flaml\\automl\\ml.py:364\u001b[0m, in \u001b[0;36mcompute_estimator\u001b[1;34m(X_train, y_train, X_val, y_val, weight_val, groups_val, budget, kf, config_dic, task, estimator_name, eval_method, eval_metric, best_val_loss, n_jobs, estimator_class, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[0;32m    361\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_val\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m y_val\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mholdout\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m==\u001b[39m eval_method:\n\u001b[1;32m--> 364\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[38;5;241m=\u001b[39m get_val_loss(\n\u001b[0;32m    365\u001b[0m         config_dic,\n\u001b[0;32m    366\u001b[0m         estimator,\n\u001b[0;32m    367\u001b[0m         X_train,\n\u001b[0;32m    368\u001b[0m         y_train,\n\u001b[0;32m    369\u001b[0m         X_val,\n\u001b[0;32m    370\u001b[0m         y_val,\n\u001b[0;32m    371\u001b[0m         weight_val,\n\u001b[0;32m    372\u001b[0m         groups_val,\n\u001b[0;32m    373\u001b[0m         eval_metric,\n\u001b[0;32m    374\u001b[0m         task,\n\u001b[0;32m    375\u001b[0m         labels\u001b[38;5;241m=\u001b[39mfit_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_list\u001b[39m\u001b[38;5;124m\"\u001b[39m),  \u001b[38;5;66;03m# pass the label list on to compute the evaluation metric\u001b[39;00m\n\u001b[0;32m    376\u001b[0m         budget\u001b[38;5;241m=\u001b[39mbudget,\n\u001b[0;32m    377\u001b[0m         log_training_metric\u001b[38;5;241m=\u001b[39mlog_training_metric,\n\u001b[0;32m    378\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m    379\u001b[0m         free_mem_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    380\u001b[0m     )\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    382\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mevaluate_model_CV(\n\u001b[0;32m    383\u001b[0m         config_dic,\n\u001b[0;32m    384\u001b[0m         estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         free_mem_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    395\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flaml\\automl\\ml.py:516\u001b[0m, in \u001b[0;36mget_val_loss\u001b[1;34m(config, estimator, X_train, y_train, X_val, y_val, weight_val, groups_val, eval_metric, task, labels, budget, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[0;32m    511\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# if groups_val is not None:\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m#     fit_kwargs['groups_val'] = groups_val\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m#     fit_kwargs['X_val'] = X_val\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m#     fit_kwargs['y_val'] = y_val\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, budget\u001b[38;5;241m=\u001b[39mbudget, free_mem_ratio\u001b[38;5;241m=\u001b[39mfree_mem_ratio, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    517\u001b[0m val_loss, metric_for_logging, pred_time, _ \u001b[38;5;241m=\u001b[39m _eval_estimator(\n\u001b[0;32m    518\u001b[0m     config,\n\u001b[0;32m    519\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    530\u001b[0m     fit_kwargs,\n\u001b[0;32m    531\u001b[0m )\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_results\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flaml\\automl\\model.py:1592\u001b[0m, in \u001b[0;36mLGBMEstimator.fit\u001b[1;34m(self, X_train, y_train, budget, free_mem_ratio, **kwargs)\u001b[0m\n\u001b[0;32m   1590\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mset_params(callbacks\u001b[38;5;241m=\u001b[39mcallbacks[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X_train, y_train, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1593\u001b[0m best_iteration \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mget_booster(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1595\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, XGBoostSklearnEstimator)\n\u001b[0;32m   1596\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mbest_iteration_\n\u001b[0;32m   1597\u001b[0m )\n\u001b[0;32m   1598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_iteration \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m best_iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flaml\\automl\\model.py:236\u001b[0m, in \u001b[0;36mBaseEstimator._fit\u001b[1;34m(self, X_train, y_train, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;66;03m# groups_val = kwargs.get('groups_val')\u001b[39;00m\n\u001b[0;32m    229\u001b[0m         \u001b[38;5;66;03m# if groups_val is not None:\u001b[39;00m\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;66;03m#     kwargs['eval_group'] = [group_counts(groups_val)]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;66;03m#     kwargs['verbose'] = False\u001b[39;00m\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;66;03m#     del kwargs['groups_val'], kwargs['X_val'], kwargs['y_val']\u001b[39;00m\n\u001b[0;32m    235\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess(X_train)\n\u001b[1;32m--> 236\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m==\u001b[39m logging\u001b[38;5;241m.\u001b[39mDEBUG:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# xgboost 1.6 doesn't display all the params in the model str\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflaml.automl.model - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fit started with params \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# Cell 1: Complete FLAML AutoML Workflow\n",
    "\n",
    "# Import necessary libraries\n",
    "from flaml import AutoML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = data.drop(columns=['hospital_death'])\n",
    "y = data['hospital_death']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n",
    "\n",
    "# Handle class imbalance using SMOTE (if applicable)\n",
    "if y_train.value_counts().min() / y_train.value_counts().max() < 0.5:\n",
    "    print(\"\\nApplying SMOTE to handle class imbalance...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    print(f\"After SMOTE, training features shape: {X_train_smote.shape}\")\n",
    "    print(f\"After SMOTE, training target distribution:\\n{pd.Series(y_train_smote).value_counts()}\")\n",
    "else:\n",
    "    print(\"\\nClass imbalance is not significant. Proceeding without SMOTE.\")\n",
    "    X_train_smote, y_train_smote = X_train, y_train\n",
    "\n",
    "# Initialize FLAML AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "# Specify FLAML AutoML settings\n",
    "automl_settings = {\n",
    "    \"time_budget\": 300,    # Time budget in seconds (e.g., 5 minutes)\n",
    "    \"metric\": 'f1',        # Primary metric to optimize\n",
    "    \"task\": 'classification',\n",
    "    \"log_file_name\": 'automl_flaml.log',  # Log file\n",
    "    \"verbose\": 1,          # Show progress logs\n",
    "    # \"estimator_list\": ['lr', 'rf', 'xgboost'],  # Optional: Specify estimators to consider\n",
    "}\n",
    "\n",
    "# Train FLAML AutoML model\n",
    "print(\"\\nTraining FLAML AutoML model...\")\n",
    "automl.fit(X_train=X_train_smote, y_train=y_train_smote, **automl_settings)\n",
    "print(\"FLAML AutoML training completed.\")\n",
    "\n",
    "# View the best model\n",
    "print(f\"\\nBest Model: {automl.model}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = automl.predict(X_test)\n",
    "y_pred_proba = automl.predict_proba(X_test)[:,1]  # Probability estimates for the positive class\n",
    "\n",
    "# Evaluation with default threshold (0.5)\n",
    "print(\"\\n=== FLAML AutoML Model Evaluation ===\")\n",
    "print(\"Classification Report with Default Threshold (0.5):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate ROC AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Function to find optimal threshold based on desired recall\n",
    "def find_threshold_for_recall(y_true, y_probs, desired_recall):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_probs)\n",
    "    # Iterate through thresholds to find the first threshold where recall >= desired_recall\n",
    "    for thresh, rec in zip(thresholds, recall):\n",
    "        if rec >= desired_recall:\n",
    "            return thresh\n",
    "    return 0.5  # Default threshold if desired recall not achievable\n",
    "\n",
    "# Define desired recall\n",
    "desired_recall = 0.90  # 90% Recall\n",
    "\n",
    "# Find optimal threshold\n",
    "optimal_threshold = find_threshold_for_recall(y_test, y_pred_proba, desired_recall)\n",
    "print(f\"\\nOptimal Threshold for Desired Recall of {desired_recall*100:.0f}%: {optimal_threshold:.2f}\")\n",
    "\n",
    "# Apply optimal threshold to obtain new predictions\n",
    "y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# Classification report with optimal threshold\n",
    "print(\"\\n=== FLAML AutoML Model Evaluation at Optimal Threshold ===\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_optimal, digits=4))\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr, tpr, roc_thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})', color='blue')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - FLAML AutoML Model')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall Curve\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f'PR Curve (AUC = {pr_auc:.4f})', color='green')\n",
    "plt.scatter(\n",
    "    recall[np.argmax(2*(precision*recall)/(precision+recall+1e-6))],\n",
    "    precision[np.argmax(2*(precision*recall)/(precision+recall+1e-6))],\n",
    "    color='red',\n",
    "    label=f'Optimal Threshold = {optimal_threshold:.2f}'\n",
    ")\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - FLAML AutoML Model')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")\n",
    "\n",
    "# Plot Confusion Matrix at Optimal Threshold\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_optimal)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(\n",
    "    conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "    yticklabels=['Actual Negative', 'Actual Positive']\n",
    ")\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix at Optimal Threshold - FLAML AutoML Model')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252bac0c",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1732072257185,
     "user": {
      "displayName": "Grayson K Merritt",
      "userId": "01135952421235413590"
     },
     "user_tz": 360
    },
    "id": "252bac0c"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
